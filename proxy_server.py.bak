#!/usr/bin/env python3
"""
Enhanced OpenAI API Proxy Server for CCC (Covenant Command Cycle) - Stage 2

This Flask server acts as a secure proxy to the OpenAI API with memory capabilities,
protecting the API key and providing controlled access to AI capabilities with
persistent context retention.
"""

import os
import sys
import json
import logging
import asyncio
import threading
import time
from flask import Flask, request, jsonify
from flask_cors import CORS
import requests
from dotenv import load_dotenv

# Add src directory to path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Load environment variables from .env file
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize Flask app
app = Flask(__name__)
CORS(app)  # Enable CORS for frontend communication

# Configuration
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
OPENAI_API_BASE = 'https://api.openai.com/v1'
HOST = '127.0.0.1'  # Back to localhost for testing
PORT = 8000  # Try a different port

if not OPENAI_API_KEY:
    logger.error("OPENAI_API_KEY environment variable is not set!")
    raise ValueError("OPENAI_API_KEY is required but not found in environment variables")

# Initialize memory service (global variables)
server_start_time = time.time()
memory_dal = None
memory_service = None
memory_initialized = False
memory_initializing = False

async def initialize_memory_service():
    """Initialize memory service"""
    global memory_dal, memory_service, memory_initialized, memory_initializing
    
    if memory_initializing:
        logger.info("Memory service initialization already in progress...")
        return False
        
    memory_initializing = True
    
    try:
        from src.memory.database import MemoryDAL
        from src.services.memory_service import MemoryService
        
        db_path = os.getenv('CCC_DATABASE_PATH', 'ccc_memory.db')
        memory_dal = MemoryDAL(db_path)
        await memory_dal.initialize_database()
        memory_service = MemoryService(memory_dal)
        logger.info("Memory service initialized successfully")
        memory_initialized = True
        return True
    except Exception as e:
        logger.warning(f"Memory service initialization failed (Stage 1 fallback): {e}")
        memory_initialized = False
        return False
    finally:
        memory_initializing = False


def initialize_memory_service_background():
    """Initialize memory service in background thread"""
    global memory_dal, memory_service, memory_initialized, memory_initializing
    
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        logger.info("[MEMORY] Starting memory service initialization in background...")
        
        # Add timeout for initialization
        try:
            # Create a future for the initialization
            future = asyncio.ensure_future(initialize_memory_service(), loop=loop)
            # Run with a timeout of 60 seconds
            result = loop.run_until_complete(asyncio.wait_for(future, timeout=60.0))
            
            if memory_initialized:
                logger.info("[MEMORY] Memory service: ENABLED")
            else:
                logger.info("[MEMORY] Memory service: DISABLED")
                
        except asyncio.TimeoutError:
            logger.error("[MEMORY] Memory service initialization timed out after 60 seconds")
            memory_initializing = False
            memory_initialized = False
            
    except Exception as e:
        logger.error(f"Memory service initialization error: {e}")
        logger.info("[MEMORY] Memory service: DISABLED (error during initialization)")
        memory_initializing = False
        memory_initialized = False
    finally:
        loop.close()


@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    global memory_service, memory_initialized, memory_initializing
    
    status = "initializing" if memory_initializing else ("available" if memory_initialized else "unavailable")
    
    return jsonify({
        'status': 'healthy',
        'service': 'CCC OpenAI Proxy',
        'version': '2.0.0',
        'memory_service': status,
        'stage': '2' if memory_initialized else '1'
    })


# Stage 2 Memory Endpoints
@app.route('/api/v2/sessions', methods=['POST'])
def create_session():
    """Create new memory session"""
    try:
        if not memory_service:
            return jsonify({'error': 'Memory service not available'}), 503
        
        data = request.get_json() or {}
        user_preferences = data.get('user_preferences', {})
        
        # Run async function in sync context
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            session = loop.run_until_complete(
                memory_service.initialize_session(user_preferences)
            )
            return jsonify(session.to_dict())
        finally:
            loop.close()
            
    except Exception as e:
        logger.error(f"Failed to create session: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/v2/sessions/<session_id>', methods=['GET'])
def get_session(session_id):
    """Get session information"""
    try:
        if not memory_service:
            return jsonify({'error': 'Memory service not available'}), 503
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            session = loop.run_until_complete(
                memory_service.get_session(session_id)
            )
            if session:
                return jsonify(session.to_dict())
            else:
                return jsonify({'error': 'Session not found'}), 404
        finally:
            loop.close()
            
    except Exception as e:
        logger.error(f"Failed to get session: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/v2/sessions/<session_id>/causal', methods=['GET'])
def get_causal_context(session_id):
    """Get causal narrative context for a session"""
    try:
        if not memory_service:
            return jsonify({'error': 'Memory service not available'}), 503
        
        query = request.args.get('query', '')
        if not query:
            return jsonify({'error': 'Query parameter required'}), 400
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            # Get causal context from enhanced memory service
            context = loop.run_until_complete(
                memory_service.get_relevant_context(session_id, query, 10)
            )
            
            # Return focused causal information
            return jsonify({
                'session_id': session_id,
                'query': query,
                'causal_narrative': context.get('causal_narrative', 'No causal context available'),
                'traditional_summary': context.get('context_summary', ''),
                'total_conversations': context.get('total_conversations', 0),
                'agent_insights': {
                    agent: {
                        'interaction_count': state.get('interaction_count', 0),
                        'preferred_topics': list(state.get('preferred_topics', {}).keys())[:5]
                    }
                    for agent, state in context.get('agent_states', {}).items()
                }
            })
        finally:
            loop.close()
            
    except Exception as e:
        logger.error(f"Failed to get causal context: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/v2/sessions/<session_id>/context', methods=['GET'])
def get_session_context(session_id):
    """Get relevant context for a session"""
    try:
        if not memory_service:
            return jsonify({'error': 'Memory service not available'}), 503
        
        directive = request.args.get('directive', '')
        max_turns = int(request.args.get('max_turns', 10))
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            context = loop.run_until_complete(
                memory_service.get_relevant_context(session_id, directive, max_turns)
            )
            return jsonify(context)
        finally:
            loop.close()
            
    except Exception as e:
        logger.error(f"Failed to get session context: {e}")
        return jsonify({'error': str(e)}), 500


# Enhanced Chat Completions with Memory (v2 endpoint)
@app.route('/v2/chat/completions', methods=['POST'])
def enhanced_chat_completions():
    """
    Enhanced chat completions with memory support
    Backward compatible with v1 when memory options not provided
    """
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No JSON data provided'}), 400
        
        # Extract memory options
        memory_options = data.pop('memory_options', {})
        session_id = data.pop('session_id', None)
        
        # If memory is requested but not available, fall back to regular completion
        if memory_options and not memory_service:
            logger.warning("Memory requested but service unavailable, falling back to Stage 1")
            memory_options = {}
            session_id = None
        
        # Handle memory-enhanced request
        if memory_options and session_id and memory_service:
            return handle_memory_enhanced_completion(data, session_id, memory_options)
        else:
            # Fall back to regular completion (Stage 1 behavior)
            return handle_regular_completion(data)
            
    except Exception as e:
        logger.error(f"Enhanced chat completion error: {e}")
        return jsonify({'error': str(e)}), 500


def handle_memory_enhanced_completion(data, session_id, memory_options):
    """Handle memory-enhanced chat completion"""
    try:
        # Get current directive from messages
        messages = data.get('messages', [])
        if not messages:
            return jsonify({'error': 'No messages provided'}), 400
        
        current_directive = messages[-1].get('content', '') if messages else ''
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            # Get relevant context if requested
            if memory_options.get('use_context', False):
                context = loop.run_until_complete(
                    memory_service.get_relevant_context(
                        session_id, 
                        current_directive,
                        memory_options.get('max_context_turns', 10)
                    )
                )
                
                # Debug logging for causal memory
                causal_narrative = context.get('causal_narrative', 'None retrieved')
                logger.info(f"CAUSAL DEBUG - Session {session_id[:8]}: Retrieved narrative length: {len(causal_narrative)} chars")
                logger.info(f"CAUSAL DEBUG - Narrative preview: {causal_narrative[:100]}...")
                
                # Add enhanced context to messages if available
                context_parts = []
                
                # Add traditional context summary
                if context.get('context_summary'):
                    context_parts.append(f"Previous conversation context: {context['context_summary']}")
                
                # Add causal narrative for enhanced reasoning - FIXED LOGIC
                causal_narrative = context.get('causal_narrative', '')
                if (causal_narrative and 
                    causal_narrative.strip() and 
                    causal_narrative not in [
                        'Causal reasoning not available', 
                        'No relevant causal context found in memory.',
                        'Causal memory not available',
                        'Error retrieving causal context'
                    ]):
                    context_parts.append(f"Causal Context Chain: {causal_narrative}")
                
                # Add agent learning context
                agent_context = []
                for agent, state in context.get('agent_states', {}).items():
                    if state.get('preferred_topics'):
                        top_topics = sorted(state['preferred_topics'].items(), key=lambda x: x[1], reverse=True)[:3]
                        topics_str = ', '.join([topic for topic, _ in top_topics])
                        agent_context.append(f"{agent.title()} frequently discusses: {topics_str}")
                
                if agent_context:
                    context_parts.append("Agent learning insights: " + "; ".join(agent_context))
                
                # Prioritize causal narrative in context injection
                if context_parts:
                    # Reorder to prioritize causal reasoning
                    causal_parts = [part for part in context_parts if part.startswith("Causal Context Chain")]
                    other_parts = [part for part in context_parts if not part.startswith("Causal Context Chain")]
                    
                    enhanced_context = "\n\n".join(causal_parts + other_parts)
                    context_message = {
                        'role': 'system',
                        'content': f"[CCC SUPERVISOR MODE - CAUSAL MEMORY ACTIVE]\n\n{enhanced_context}\n\nUSE THIS CAUSAL CONTEXT TO INFORM YOUR ANALYSIS. The causal chain shows how previous events led to current circumstances. Apply this knowledge in your supervision."
                    }
                    data['messages'] = [context_message] + data['messages']
                    logger.info(f"Injected causal memory context for session {session_id[:8]}...")
            
            # Make OpenAI API call
            headers = {
                'Authorization': f'Bearer {OPENAI_API_KEY}',
                'Content-Type': 'application/json'
            }
            
            logger.info(f"Memory-enhanced chat completion for session {session_id[:8]}...")
            
            response = requests.post(
                f'{OPENAI_API_BASE}/chat/completions',
                json=data,
                headers=headers,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                
                # Store response in memory if requested
                if memory_options.get('auto_store_response', False):
                    try:
                        # Create conversation if new
                        conversation = loop.run_until_complete(
                            memory_service.create_conversation(session_id, current_directive)
                        )
                        
                        if conversation:
                            # Store the AI response - FIXED: Use valid agent name
                            ai_content = result['choices'][0]['message']['content']
                            # Determine which agent is responding based on context
                            responding_agent = 'beatrice'  # Default to supervisor agent
                            if 'execute' in current_directive.lower() or 'implement' in current_directive.lower():
                                responding_agent = 'codey'
                            
                            loop.run_until_complete(
                                memory_service.store_conversation_turn(
                                    session_id,
                                    conversation.conversation_id,
                                    responding_agent,
                                    ai_content,
                                    {
                                        'model_used': data.get('model', 'unknown'),
                                        'temperature': data.get('temperature', 0.7),
                                        'execution_time_ms': response.elapsed.total_seconds() * 1000,
                                        'enhanced_with_causal_reasoning': True
                                    }
                                )
                            )
                    except Exception as e:
                        logger.warning(f"Failed to store response in memory: {e}")
                
                return jsonify(result)
            else:
                error_data = response.json() if response.content else {'error': 'Unknown error'}
                return jsonify(error_data), response.status_code
                
        finally:
            loop.close()
            
    except Exception as e:
        logger.error(f"Memory-enhanced completion failed: {e}")
        # Add detailed causal memory status
        if hasattr(memory_service, 'causal_memory'):
            causal_available = memory_service.causal_memory._is_available()
            logger.error(f"Causal Memory Core available: {causal_available}")
        return jsonify({'error': f'Memory enhancement failed: {str(e)}'}), 500


def handle_regular_completion(data):
    """Handle regular chat completion (Stage 1 behavior)"""
    try:
        # Prepare headers for OpenAI API
        headers = {
            'Authorization': f'Bearer {OPENAI_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        # Log the request (excluding sensitive data)
        logger.info(f"Proxying request to OpenAI API: {data.get('model', 'unknown')}")
        
        # Forward the request to OpenAI API
        response = requests.post(
            f'{OPENAI_API_BASE}/chat/completions',
            json=data,
            headers=headers,
            timeout=30
        )
        
        # Return the response
        if response.status_code == 200:
            logger.info("Successfully proxied request to OpenAI")
            return jsonify(response.json())
        else:
            logger.error(f"OpenAI API error: {response.status_code} - {response.text}")
            return jsonify({
                'error': 'OpenAI API error',
                'status_code': response.status_code,
                'message': response.text
            }), response.status_code
            
    except requests.exceptions.Timeout:
        logger.error("Request to OpenAI API timed out")
        return jsonify({'error': 'Request timeout'}), 408
    except requests.exceptions.RequestException as e:
        logger.error(f"Request error: {str(e)}")
        return jsonify({'error': 'Request failed', 'details': str(e)}), 500
    except Exception as e:
        logger.error(f"Unexpected error: {str(e)}")
        return jsonify({'error': 'Internal server error', 'details': str(e)}), 500


@app.route('/v1/chat/completions', methods=['POST'])
def chat_completions():
    """
    Proxy endpoint for OpenAI chat completions
    Forwards requests to OpenAI API with proper authentication
    """
    try:
        # Get request data
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No JSON data provided'}), 400
        
        # Prepare headers for OpenAI API
        headers = {
            'Authorization': f'Bearer {OPENAI_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        # Log the request (excluding sensitive data)
        logger.info(f"Proxying request to OpenAI API: {data.get('model', 'unknown')}")
        
        # Forward the request to OpenAI API
        response = requests.post(
            f'{OPENAI_API_BASE}/chat/completions',
            json=data,
            headers=headers,
            timeout=30
        )
        
        # Return the response
        if response.status_code == 200:
            logger.info("Successfully proxied request to OpenAI")
            return jsonify(response.json())
        else:
            logger.error(f"OpenAI API error: {response.status_code} - {response.text}")
            return jsonify({
                'error': 'OpenAI API error',
                'status_code': response.status_code,
                'message': response.text
            }), response.status_code
            
    except requests.exceptions.Timeout:
        logger.error("Request to OpenAI API timed out")
        return jsonify({'error': 'Request timeout'}), 408
    except requests.exceptions.RequestException as e:
        logger.error(f"Request error: {str(e)}")
        return jsonify({'error': 'Request failed', 'details': str(e)}), 500
    except Exception as e:
        logger.error(f"Unexpected error: {str(e)}")
        return jsonify({'error': 'Internal server error', 'details': str(e)}), 500


@app.errorhandler(404)
def not_found(error):
    """Handle 404 errors"""
    return jsonify({'error': 'Endpoint not found'}), 404


@app.errorhandler(500)
def internal_error(error):
    """Handle 500 errors"""
    return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/v2/status', methods=['GET'])
def memory_service_status():
    """Get detailed memory service status"""
    global memory_service, memory_initialized, memory_initializing
    
    status = {
        'memory_service': {
            'status': "initializing" if memory_initializing else ("available" if memory_initialized else "unavailable"),
            'initialization_complete': memory_initialized,
            'initialization_in_progress': memory_initializing
        },
        'server': {
            'version': '2.0.0',
            'stage': '2' if memory_initialized else '1',
            'uptime_seconds': int(time.time() - server_start_time)
        }
    }
    
    # Add detailed memory service info if available
    if memory_service:
        try:
            # Get database stats if available
            db_stats = {}
            if memory_dal:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    stats = loop.run_until_complete(memory_dal.get_stats())
                    db_stats = {
                        'sessions_count': stats.get('sessions_count', 0),
                        'conversations_count': stats.get('conversations_count', 0),
                        'turns_count': stats.get('turns_count', 0)
                    }
                except Exception as e:
                    db_stats = {'error': str(e)}
                finally:
                    loop.close()
            
            # Check causal memory status
            causal_status = "unavailable"
            if hasattr(memory_service, 'causal_memory'):
                causal_status = "available" if memory_service.causal_memory._is_available() else "unavailable"
            
            status['memory_service'].update({
                'database': db_stats,
                'causal_memory': causal_status
            })
        except Exception as e:
            status['memory_service']['error'] = str(e)
    
    return jsonify(status)


if __name__ == '__main__':
    # Start the server first, then initialize memory in background
    logger.info("[START] Covenant API Proxy is starting...")
    logger.info(f"[SERVER] Server running on http://{HOST}:{PORT}")
    logger.info("[NOTE] Make sure OPENAI_API_KEY is set in your environment variables")
    
    # Start memory service initialization in a background thread
    memory_thread = threading.Thread(target=initialize_memory_service_background)
    memory_thread.daemon = True
    memory_thread.start()
    
    # Register signal handlers for graceful shutdown
    import signal
    import atexit
    
    def cleanup_resources():
        """Clean up resources before shutdown"""
        logger.info("[SERVER] Shutting down server...")
        if memory_dal and hasattr(memory_dal, 'close'):
            logger.info("[MEMORY] Closing database connections...")
            try:
                # Create a new event loop for cleanup
                cleanup_loop = asyncio.new_event_loop()
                asyncio.set_event_loop(cleanup_loop)
                cleanup_loop.run_until_complete(memory_dal.close())
                cleanup_loop.close()
                logger.info("[MEMORY] Database connections closed successfully")
            except Exception as e:
                logger.error(f"Error closing database connections: {e}")
    
    # Register the cleanup function to be called on exit
    atexit.register(cleanup_resources)
    
    # Handle SIGINT (Ctrl+C) and SIGTERM
    def signal_handler(sig, frame):
        logger.info(f"Received signal {sig}, shutting down...")
        cleanup_resources()
        sys.exit(0)
    
    # Register signal handlers if on Unix-like system
    if hasattr(signal, 'SIGINT'):
        signal.signal(signal.SIGINT, signal_handler)
    if hasattr(signal, 'SIGTERM'):
        signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        app.run(
            host=HOST,
            port=PORT,
            debug=True,
            use_reloader=False,
            threaded=True  # Enable threading for the Flask app
        )
    except Exception as e:
        logger.error(f"Failed to start Flask server: {e}")
        logger.error("This could be due to:")
        logger.error("- Port 8000 already in use")
        logger.error("- Windows Firewall blocking the connection")
        logger.error("- Insufficient permissions")
        sys.exit(1)
